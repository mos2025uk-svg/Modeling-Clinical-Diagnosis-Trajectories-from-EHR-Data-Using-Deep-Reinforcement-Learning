# --------------------------------------------------
# Imports
# --------------------------------------------------
import numpy as np
import pandas as pd
import tensorflow as tf

from tensorflow.keras import layers, models, optimizers
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    f1_score,
    roc_auc_score,
)

# --------------------------------------------------
# Configuration
# --------------------------------------------------
TRAIN_PATH = "data/train_set_basic.csv"
TEST_PATH = "data/test_set_constant.csv"

FEATURE_COLUMNS = [
    "hemoglobin", "ferritin", "ret_count", "segmented_neutrophils", "tibc",
    "mcv", "serum_iron", "rbc", "gender", "creatinine", "cholestrol",
    "copper", "ethanol", "folate", "glucose", "hematocrit", "tsat",
]

TARGET_COLUMN = "label"
EPOCHS = 50
BATCH_SIZE = 32
LEARNING_RATE = 1e-3
VALIDATION_SPLIT = 0.2
RANDOM_SEED = 42

tf.random.set_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

# --------------------------------------------------
# Load Data
# --------------------------------------------------
train_df = pd.read_csv(TRAIN_PATH)
test_df = pd.read_csv(TEST_PATH)

print("Train Data Columns:", train_df.columns)
print("Test Data Columns:", test_df.columns)

missing_features = [f for f in FEATURE_COLUMNS if f not in train_df.columns]
if missing_features:
    raise ValueError(f"Missing feature columns: {missing_features}")

# --------------------------------------------------
# Prepare Datasets
# --------------------------------------------------
X_train = train_df[FEATURE_COLUMNS].values
y_train = train_df[TARGET_COLUMN].values

X_test = test_df[FEATURE_COLUMNS].values
y_test = test_df[TARGET_COLUMN].values

# Standardization
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# One-hot encoding
num_classes = len(np.unique(y_train))
y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes)
y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes)

# --------------------------------------------------
# Model Definition
# --------------------------------------------------
model = models.Sequential([
    layers.Input(shape=(len(FEATURE_COLUMNS),)),
    layers.Dense(64, activation="relu"),
    layers.Dense(64, activation="relu"),
    layers.Dense(num_classes, activation="softmax"),
])

model.compile(
    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),
    loss="categorical_crossentropy",
    metrics=["accuracy"],
)

model.summary()

# --------------------------------------------------
# Training
# --------------------------------------------------
history = model.fit(
    X_train,
    y_train_cat,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_split=VALIDATION_SPLIT,
    verbose=1,
)

# --------------------------------------------------
# Evaluation
# --------------------------------------------------
y_pred_proba = model.predict(X_test)
y_pred = np.argmax(y_pred_proba, axis=1)

accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average="weighted")
roc_auc = roc_auc_score(y_test_cat, y_pred_proba, multi_class="ovr")

print(f"\nAccuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"ROC AUC Score: {roc_auc:.4f}")

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:\n")
print(confusion_matrix(y_test, y_pred))
